# Multi-Agent Support Chatbot

A Multi-agent orchestration system that intelligently routes customer inquiries to specialized RAG agents (HR, IT Support, Finance, Legal) using LangChain v1 and Langfuse for observability.

> ğŸ“– For a complete overview of features and capabilities, see [ARCHITECTURE.md](./docs/ARCHITECTURE.md#features).

## ğŸ¬ Demo

Demo showing single run question with full structured output and the chat mode:


https://github.com/user-attachments/assets/585e602a-c096-4436-a9f5-5cabd1a87d58



## ğŸ“‹ Prerequisites

- **Node.js** 22+
- **npm**
- **OpenAI API Key** - Required for LLM and embeddings
- **Langfuse Account** (optional but recommended) - For observability
- **Vector Store** - Choose one:
  - **ChromaDB** (recommended) - See [ChromaDB Setup](#chromadb-setup) section below
  - **Memory** (alternative) - No additional setup required

## ğŸ› ï¸ Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd company-support-chatbot
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Configure environment variables:**
   ```bash
   cp .env.example .env
   ```

4. **Edit `.env` with your configuration:**
   
   **Required:**
   ```env
   OPENAI_API_KEY=your-api-key-here
   ```
   
   **Optional (but recommended):**
   ```env
   # Langfuse for observability - omit if you don't need tracing
   LANGFUSE_ENABLED=true
   LANGFUSE_PUBLIC_KEY=pk-lf-xxx
   LANGFUSE_SECRET_KEY=sk-lf-xxx
   LANGFUSE_HOST=https://cloud.langfuse.com
   ```
   
   **Note**: All other configuration variables are optional and have sensible defaults. See the [Configuration](#-configuration) section below for all available options. Langfuse is optional but recommended for observability - the system will work without it, but you won't have tracing and evaluation features.

## ğŸ¯ Quick Start

### 1. Prepare Your Documents

Place domain-specific documentation in the `data/` directory:

```
data/
â”œâ”€â”€ hr_docs/          # HR documentation
â”œâ”€â”€ it_docs/          # IT Support documentation
â”œâ”€â”€ finance_docs/     # Finance documentation
â””â”€â”€ legal_docs/       # Legal documentation
```

Each directory should contain at least 50 chunks of domain-specific content in `.txt` or `.md` format.

### 2. Build Vector Indexes

Build vector indexes for all domains:

```bash
npm run dev:build-index
```

This will:
- Load documents from each domain directory
- Split them into chunks
- Generate embeddings
- Store in vector stores (ChromaDB or Memory)

### 3. Query the System

#### Single Query Mode

Ask a single question using the main script:

```bash
npm run dev -- "What are the company's health insurance benefits?"
```

This will:
- Classify the intent
- Route to the appropriate agent
- Return a JSON response with the answer, sources, and evaluation

#### Interactive Conversation Mode

Start an interactive conversation session:

```bash
npm run dev:chat
# or
npm run chat
```

This mode:
- Maintains conversation history across multiple turns
- Supports commands: `exit`, `quit`, `bye`, `clear`, `help`
- Uses conversation memory (buffer or summary based on config)

#### Test Suite

Run the test suite to validate intent classification:

```bash
npm run dev:test
```

This will:
- Run all test queries from `tests/test-queries.json`
- Check intent classification accuracy
- Evaluate response quality
- Generate a summary report with accuracy metrics

## ğŸ“ Project Structure

```
company-support-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # Main entry point (CLI mode)
â”‚   â”œâ”€â”€ cli/                        # CLI interfaces
â”‚   â”‚   â”œâ”€â”€ conversation.ts         # Interactive conversation mode
â”‚   â”‚   â””â”€â”€ index.ts                # CLI exports
â”‚   â”œâ”€â”€ orchestrator/               # Orchestrator agent
â”‚   â”‚   â”œâ”€â”€ agent.ts                # Orchestrator implementation
â”‚   â”‚   â”œâ”€â”€ classifier.ts           # Intent classification
â”‚   â”‚   â”œâ”€â”€ types.ts                # Orchestrator types
â”‚   â”‚   â””â”€â”€ index.ts                # Orchestrator exports
â”‚   â”œâ”€â”€ agents/                     # Specialized RAG agents
â”‚   â”‚   â”œâ”€â”€ base-agent.ts           # Base agent class
â”‚   â”‚   â”œâ”€â”€ hr-agent.ts             # HR agent
â”‚   â”‚   â”œâ”€â”€ it-agent.ts             # IT Support agent
â”‚   â”‚   â”œâ”€â”€ finance-agent.ts        # Finance agent
â”‚   â”‚   â”œâ”€â”€ legal-agent.ts          # Legal agent
â”‚   â”‚   â”œâ”€â”€ factory.ts              # Agent factory & lazy loading
â”‚   â”‚   â””â”€â”€ index.ts                # Agent exports
â”‚   â”œâ”€â”€ evaluator/                  # Evaluator agent (BONUS)
â”‚   â”‚   â”œâ”€â”€ agent.ts                # Evaluator implementation
â”‚   â”‚   â”œâ”€â”€ scorer.ts               # Langfuse score integration
â”‚   â”‚   â””â”€â”€ index.ts                # Evaluator exports
â”‚   â”œâ”€â”€ chains/                     # LangChain chains
â”‚   â”‚   â””â”€â”€ rag-chain.ts            # Base RAG chain with LCEL
â”‚   â”œâ”€â”€ safety/                     # Safety middleware
â”‚   â”‚   â”œâ”€â”€ middleware.ts           # LangChain safety middleware
â”‚   â”‚   â”œâ”€â”€ moderation.ts           # Content moderation (OpenAI)
â”‚   â”‚   â”œâ”€â”€ pii.ts                  # PII detection & redaction
â”‚   â”‚   â”œâ”€â”€ injection.ts            # Injection detection
â”‚   â”‚   â””â”€â”€ index.ts                # Safety exports
â”‚   â”œâ”€â”€ monitoring/                 # Observability
â”‚   â”‚   â”œâ”€â”€ langfuse.ts             # Langfuse integration
â”‚   â”‚   â”œâ”€â”€ callbacks.ts            # LangChain callbacks
â”‚   â”‚   â”œâ”€â”€ metrics.ts              # Metrics collection
â”‚   â”‚   â””â”€â”€ tracing.ts              # Distributed tracing
â”‚   â”œâ”€â”€ retrievers/                 # Retrieval strategies
â”‚   â”‚   â”œâ”€â”€ similarity.ts           # Similarity search retriever
â”‚   â”‚   â”œâ”€â”€ mmr.ts                  # MMR (Maximal Marginal Relevance)
â”‚   â”‚   â”œâ”€â”€ compression.ts          # Context compression retriever
â”‚   â”‚   â””â”€â”€ index.ts                # Retriever factory
â”‚   â”œâ”€â”€ vector-stores/              # Vector store implementations
â”‚   â”‚   â”œâ”€â”€ chroma.ts               # ChromaDB integration
â”‚   â”‚   â”œâ”€â”€ memory.ts               # In-memory vector store
â”‚   â”‚   â””â”€â”€ index.ts                # Vector store factory
â”‚   â”œâ”€â”€ embeddings/                 # Embedding providers
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.ts           # OpenAI embeddings
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ llm/                        # LLM providers
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.ts           # OpenAI LLM
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ loaders/                    # Document loaders
â”‚   â”‚   â””â”€â”€ directory-loader.ts     # Directory-based loader
â”‚   â”œâ”€â”€ splitters/                  # Text splitters
â”‚   â”‚   â””â”€â”€ index.ts                # Text splitter factory
â”‚   â”œâ”€â”€ prompts/                    # Prompt templates
â”‚   â”‚   â”œâ”€â”€ rag.ts                  # RAG prompts
â”‚   â”‚   â”œâ”€â”€ classifier.ts           # Classification prompts
â”‚   â”‚   â”œâ”€â”€ evaluator.ts            # Evaluation prompts
â”‚   â”‚   â”œâ”€â”€ compression.ts          # Compression prompts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ cache/                      # Caching layer
â”‚   â”‚   â”œâ”€â”€ in-memory.ts            # In-memory cache
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ memory/                     # Conversation memory
â”‚   â”‚   â””â”€â”€ index.ts                # Memory management
â”‚   â”œâ”€â”€ config/                     # Configuration
â”‚   â”‚   â”œâ”€â”€ env.ts                  # Environment config with Zod
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ types/                      # TypeScript types
â”‚   â”‚   â”œâ”€â”€ schemas.ts              # Zod schemas
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ utils/                      # Utility functions
â”‚   â”‚   â”œâ”€â”€ circuit-breaker.ts      # Circuit breaker pattern
â”‚   â”‚   â”œâ”€â”€ retry.ts                # Retry with backoff
â”‚   â”‚   â”œâ”€â”€ timeout.ts              # Timeout handling
â”‚   â”‚   â”œâ”€â”€ errors.ts               # Custom error classes
â”‚   â”‚   â””â”€â”€ validation.ts           # Validation utilities
â”‚   â””â”€â”€ logger.ts                   # Pino logger setup
â”œâ”€â”€ data/                           # Document collections
â”‚   â”œâ”€â”€ hr_docs/                    # HR documentation
â”‚   â”œâ”€â”€ it_docs/                    # IT Support documentation
â”‚   â”œâ”€â”€ finance_docs/               # Finance documentation
â”‚   â””â”€â”€ legal_docs/                 # Legal documentation
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”œâ”€â”€ build-index.ts              # Build vector indexes
â”‚   â””â”€â”€ test-system.ts              # Run test queries
â”œâ”€â”€ tests/                          # Test suite
â”‚   â””â”€â”€ test-queries.json           # Test queries with expected intents
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md             # Architecture documentation
â”‚   â””â”€â”€ safety.md                   # Safety middleware documentation
â”œâ”€â”€ dist/                           # Compiled output (TypeScript)
â”œâ”€â”€ docker-compose.yml              # ChromaDB Docker setup
â”œâ”€â”€ tsconfig.json                   # TypeScript configuration
â”œâ”€â”€ vitest.config.ts                # Vitest test configuration
â”œâ”€â”€ package.json                    # Dependencies & scripts
â””â”€â”€ README.md                       # This file
```

## âš™ï¸ Configuration

All configuration is done via environment variables. See `.env.example` for all available options.

### Required Configuration

```env
# OpenAI (REQUIRED)
OPENAI_API_KEY=your-api-key-here
```

### Optional Configuration

All variables below are optional and have sensible defaults. Only set them if you need to override the defaults.

```env
# Langfuse (OPTIONAL - for observability)
# Set LANGFUSE_ENABLED=false to disable Langfuse entirely
# Omit these if you don't want tracing and evaluation features
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=pk-lf-xxx
LANGFUSE_SECRET_KEY=sk-lf-xxx
LANGFUSE_HOST=https://cloud.langfuse.com

# LLM Configuration (OPTIONAL - has defaults)
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small

# Vector Store (OPTIONAL - has defaults)
VECTOR_STORE_TYPE=chromadb
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=support_embeddings
CHROMA_SSL=false
CHROMA_API_KEY=              # Only needed for authenticated ChromaDB instances

# Retrieval (OPTIONAL - has defaults)
RETRIEVER_TYPE=similarity  # Options: similarity, mmr, compression
TOP_K=5                     # Number of documents to retrieve
SCORE_THRESHOLD=0.5         # Minimum similarity score threshold

# Chunking (OPTIONAL - has defaults)
CHUNK_SIZE=800
CHUNK_OVERLAP=100
MIN_CHUNKS=20

# Safety (OPTIONAL - has defaults)
SAFETY_ENABLED=true
SAFETY_CHECK_OUTPUT=true    # Enable output safety checks

# Performance (OPTIONAL - has defaults)
CACHE_ENABLED=true
CACHE_TTL=3600              # Cache TTL in seconds (1 hour)

# Memory (OPTIONAL - has defaults)
MEMORY_TYPE=buffer          # Options: buffer, summary, none
MEMORY_MAX_TOKENS=2000      # Max tokens for summary memory

# Logging (OPTIONAL - has defaults)
LOG_LEVEL=error              # Options: debug, info, warn, error
LOG_FORMAT=auto             # Auto-detects based on NODE_ENV
NODE_ENV=development        # Options: development, production, test
```

**Note**: Variables marked as "OPTIONAL - has defaults" can be omitted entirely. The system will use the default values shown above. Only set them if you need to customize the behavior.

## ğŸ—„ï¸ ChromaDB Setup

If you're using ChromaDB as your vector store (recommended), you need to set it up before building indexes.

### Using Docker Compose (Recommended)

The easiest way to run ChromaDB is using the provided `docker-compose.yml`:

```bash
docker-compose up -d
```

This will:
- Start ChromaDB on port 8000
- Create a persistent volume for data
- Set up health checks
- Configure automatic restarts

### Using Docker Directly

Alternatively, you can run ChromaDB directly with Docker:

```bash
docker run -p 8000:8000 chromadb/chroma
```

**Note**: This method doesn't persist data between container restarts. Use Docker Compose for production.

### Verify ChromaDB is Running

Check that ChromaDB is accessible:

```bash
curl http://localhost:8000/api/v1/heartbeat
```

You should see a response indicating ChromaDB is running.

### Configuration

Update your `.env` file with ChromaDB settings:

```env
VECTOR_STORE_TYPE=chromadb
CHROMA_HOST=localhost
CHROMA_PORT=8000
```

### Using Memory Vector Store (Alternative)

If you don't want to use ChromaDB, you can use the in-memory vector store:

```env
VECTOR_STORE_TYPE=memory
```

**Note**: The memory vector store doesn't persist data between restarts and is mainly useful for testing.

## ğŸ—ï¸ Architecture

For detailed architecture documentation, including system flow, component architecture, design patterns, and technical decisions, see [ARCHITECTURE.md](./docs/ARCHITECTURE.md).

## ğŸ§ª Testing

### Test Queries

The `tests/test-queries.json` file contains test queries with expected intents:

```bash
npm run dev:test
```

This will:
- Run all test queries
- Check intent classification accuracy
- Evaluate response quality
- Generate a summary report with accuracy percentage

### Unit Tests

Run unit tests with Vitest:

```bash
npm test              # Run tests once
npm run test:watch     # Watch mode
npm run test:coverage  # With coverage report
```

### Example Test Query

```json
{
  "question": "What are the company's health insurance benefits?",
  "expectedIntent": "hr",
  "description": "HR benefits question"
}
```

### Development Scripts

```bash
npm run build          # Compile TypeScript
npm run lint           # Run ESLint
npm run format         # Format code with Prettier
npm run format:check   # Check formatting
npm run typecheck      # Type check without emitting
```

## ğŸ”§ Troubleshooting

**ChromaDB Connection**: Verify it's running with `curl http://localhost:8000/api/v1/heartbeat` or start with `docker-compose up -d`. Use `VECTOR_STORE_TYPE=memory` as fallback.

**OpenAI API**: Ensure `OPENAI_API_KEY` is set correctly in `.env`. Check rate limits and API key format (should start with `sk-`).

**Vector Store**: Rebuild indexes with `npm run dev:build-index`. Ensure documents exist in `data/*/` directories and are in `.txt` or `.md` format.

**Environment Variables**: Verify `.env` exists and variable names are correct (case-sensitive). Restart the application after changes.

**Langfuse**: Optional - disable with `LANGFUSE_ENABLED=false` if not needed. Verify credentials and host URL if enabled.

**Debugging**: Enable debug logging with `LOG_LEVEL=debug` and check application logs. Run `npm run dev:test` to validate system behavior.

For more details, see [ARCHITECTURE.md](./docs/ARCHITECTURE.md).

## ğŸ“š Additional Documentation

- [ARCHITECTURE.md](./docs/ARCHITECTURE.md) - Detailed system architecture
- [Safety Documentation](./docs/safety.md) - Safety middleware documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

## ğŸ“ License

MIT
